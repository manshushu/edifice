{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'darknet' has no attribute 'load_net'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdarknet\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m net \u001b[39m=\u001b[39m darknet\u001b[39m.\u001b[39;49mload_net(\u001b[39m\"\u001b[39m\u001b[39myolov3.cfg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myolov3.weights\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m meta \u001b[39m=\u001b[39m darknet\u001b[39m.\u001b[39mload_meta(\u001b[39m\"\u001b[39m\u001b[39mcoco.names\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'darknet' has no attribute 'load_net'"
     ]
    }
   ],
   "source": [
    "import darknet\n",
    "import cv2\n",
    "\n",
    "net = darknet.load_net(\"yolov3.cfg\", \"yolov3.weights\", 0)\n",
    "meta = darknet.load_meta(\"coco.names\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 将OpenCV图像转换为Darknet格式的图像\n",
    "    dark_frame = darknet.make_image(frame.shape[1], frame.shape[0], 3)\n",
    "    darknet.copy_image_from_bytes(dark_frame, frame.tobytes())\n",
    "    \n",
    "    # 进行目标检测\n",
    "    results = darknet.detect_image(net, meta, dark_frame)\n",
    "    \n",
    "    # 在图像上绘制检测结果\n",
    "    for result in results:\n",
    "        x, y, w, h = result[2]\n",
    "        cv2.rectangle(frame, (int(x - w/2), int(y - h/2)), (int(x + w/2), int(y + h/2)), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, str(result[0].decode(\"utf-8\")), (int(x - w/2), int(y - h/2) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    # 显示结果\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # 按下q键退出程序\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pycharm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#读取网络配置文件和权重文件\n",
    "net=cv2.dnn.readNet(model='yolov3.weights',\n",
    "                    config='yolov3.cfg')\n",
    "#由yolo-v3的结构可知，最终有三个尺度的输出\n",
    "layerName=net.getLayerNames()\n",
    "#存储输出的三个尺度名称，用于后面进行前向推断的\n",
    "ThreeOutput_layers_name=[]\n",
    "for i in net.getUnconnectedOutLayers():\n",
    "    ThreeOutput_layers_name.append(layerName[i-1])\n",
    "\n",
    "#因为yolo-v3中检测包含80个类别，所以首先获取类别\n",
    "with open('coco.names','r') as fp:\n",
    "    classes=fp.read().splitlines()\n",
    "\n",
    "#指定过滤的置信度阈值：confidence\n",
    "Confidence_thresh=0.2\n",
    "#指定非极大值抑制的值：对候选框进行筛选\n",
    "Nms_thresh=0.35\n",
    "\n",
    "#检测的过程已经图形的绘制\n",
    "def Forward_Predict(frame):\n",
    "    # 参数情况：图像 ，归一化，缩放的大小，是否对RGB减去一个常数，R和B交换（因为R和B是反着的，所以需要交换），是否裁剪\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255, (416, 416), (0, 0, 0), swapRB=True, crop=False)\n",
    "    #获取图像的高宽\n",
    "    height,width,channel=frame.shape\n",
    "    #设置网络输入\n",
    "    net.setInput(blob)\n",
    "    #进行前向推断:采用的最后三个尺度输出层作为前向推断\n",
    "    predict=net.forward(ThreeOutput_layers_name)\n",
    "    # 存放预测框的坐标\n",
    "    boxes = []\n",
    "    #存在预测物体的置信度\n",
    "    confid_object=[]\n",
    "    #存放预测的类别\n",
    "    class_prob=[]\n",
    "    #存放预测物体的id\n",
    "    class_id=[]\n",
    "    #存放预测类别的名称\n",
    "    class_names=[]\n",
    "    #根据输出的是三个尺度，所以分别遍历三个尺度\n",
    "    for scale in predict:\n",
    "        for box in scale:\n",
    "            #获取坐标值和高宽\n",
    "            #首先获取矩形中心坐标值（这里需要映射回原图）\n",
    "            center_x=int(box[0]*width)\n",
    "            center_y=int(box[1]*height)\n",
    "            #计算框的高宽\n",
    "            w=int(box[2]*width)\n",
    "            h=int(box[3]*height)\n",
    "            #获取矩形框的左上角坐标\n",
    "            left_x=int(center_x-w/2)\n",
    "            left_y=int(center_y-h/2)\n",
    "            boxes.append([left_x,left_y,w,h])\n",
    "\n",
    "            #获取检测物体的置信度\n",
    "            confid_object.append(float(box[4]))\n",
    "            #获取概率最大值\n",
    "            #首先获取最高值概率的下标\n",
    "            index=np.argmax(box[5:])\n",
    "            class_id.append(index)\n",
    "            class_names.append(classes[index])\n",
    "            class_prob.append(box[index])\n",
    "    confidences=np.array(class_prob)*np.array(confid_object)\n",
    "    #计算非极大值抑制\n",
    "    all_index=cv2.dnn.NMSBoxes(boxes,confidences,Confidence_thresh,Nms_thresh)\n",
    "\n",
    "    #遍历，绘制矩形框\n",
    "    for i in all_index.flatten():\n",
    "        x,y,w,h=boxes[i]\n",
    "        #四舍五入，保留2位小数\n",
    "        confidence=str(round(confidences[i],2))\n",
    "        #绘制矩形框\n",
    "        cv2.rectangle(img=frame,pt1=(x,y),pt2=(x+w,y+h),\n",
    "                      color=(0,255,0),thickness=2)\n",
    "        text=class_names[i]+' '+confidence\n",
    "        cv2.putText(img=frame,text=text,org=(x,y-10),\n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1.0,color=(0,0,255),thickness=2)\n",
    "    return frame\n",
    "\n",
    "#实时的检测\n",
    "def detect_time():\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    while cap.isOpened():\n",
    "        OK,frame=cap.read()\n",
    "        if not OK:\n",
    "            break\n",
    "        #将图片进行一下翻转，因为Opencv读取的图片和我们正常是反着的\n",
    "        frame=cv2.flip(src=frame,flipCode=2)\n",
    "        frame=cv2.resize(src=frame,dsize=(416,416))\n",
    "        dst=Forward_Predict(frame)\n",
    "\n",
    "        cv2.imshow('detect',dst)\n",
    "        key=cv2.waitKey(1)\n",
    "        if key==27:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "#单张图片的检测\n",
    "def signa_Picture(image_path='images/smile.jpg'):\n",
    "    img=cv2.imread(image_path)\n",
    "    img=cv2.resize(src=img,dsize=(416,416))\n",
    "    dst=Forward_Predict(img)\n",
    "    cv2.imshow('detect',dst)\n",
    "    key=cv2.waitKey(0)\n",
    "    if key==27:\n",
    "        exit()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Pycharm')\n",
    "    # signa_Picture()\n",
    "    detect_time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 加载YOLOv3或YOLOv4\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "# 获取输出层\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# 加载类别名称\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# 设置颜色\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m# 获取检测结果\u001b[39;00m\n\u001b[0;32m     11\u001b[0m net\u001b[39m.\u001b[39msetInput(blob)\n\u001b[1;32m---> 12\u001b[0m outs \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward(output_layers)\n\u001b[0;32m     14\u001b[0m \u001b[39m# 处理检测结果\u001b[39;00m\n\u001b[0;32m     15\u001b[0m class_ids \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # 调整图像大小\n",
    "        height, width, channels = frame.shape\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "\n",
    "        # 获取检测结果\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # 处理检测结果\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    # 目标的坐标信息是相对于图像宽度和高度的比例，需要转换为像素坐标\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # 非最大抑制（去除重叠的边界框，使用置信度作为分数进行排序）\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                color = colors[class_ids[i]]\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(frame, label, (x, y - 5), font, 1, color, 2)\n",
    "\n",
    "        # 显示结果\n",
    "        cv2.imshow(\"Image\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
