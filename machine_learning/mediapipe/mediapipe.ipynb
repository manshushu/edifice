{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 获取MediaPipe的姿势估计模块\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# 获取摄像头输入\n",
    "cap = cv2.VideoCapture(0)\n",
    "def predict_action(pose_features):\n",
    "    # 使用机器学习模型识别动作\n",
    "    # 可以根据你的数据集和模型来改变这个函数实现更准确的动作识别\n",
    "    if pose_features[2] > pose_features[12] and pose_features[14] < pose_features[24]:\n",
    "        return 'Squat'\n",
    "    elif pose_features[22] < pose_features[12]:\n",
    "        return 'Raise arms'\n",
    "    else:\n",
    "        return 'Idle'\n",
    "\n",
    "# 循环获取摄像头帧\n",
    "while cap.isOpened():\n",
    "    # 读取摄像头帧并进行姿势估计\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        results = pose.process(frame)\n",
    "        \n",
    "        # 如果有检测到姿势\n",
    "        if results.pose_landmarks:\n",
    "            # 提取姿势特征\n",
    "            pose_features = []\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                pose_features.append(landmark.x)\n",
    "                pose_features.append(landmark.y)\n",
    "                pose_features.append(landmark.z)\n",
    "                \n",
    "            # 使用机器学习模型识别动作\n",
    "            action = predict_action(pose_features)\n",
    "            \n",
    "            # 在帧上显示识别结果\n",
    "            cv2.putText(frame, action, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "        # 显示帧\n",
    "        cv2.imshow('MediaPipe Pose Estimation', frame)\n",
    "\n",
    "        # 如果按下ESC键，则退出循环\n",
    "        if cv2.waitKey(10) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def predict_action(pose_features):\n",
    "    # 通过机器学习模型识别动作\n",
    "    return 'Jump'  # 假设这里返回跳跃动作的结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from playsound import playsound\n",
    "\n",
    "# 获取MediaPipe的姿势估计模块\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# 获取摄像头输入\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 加载训练好的手势识别模型\n",
    "model = tf.keras.models.load_model('handgesture.h5')\n",
    "\n",
    "# 循环获取摄像头帧\n",
    "while cap.isOpened():\n",
    "    # 读取摄像头帧并进行姿势估计\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        results = pose.process(frame)\n",
    "        \n",
    "        # 如果有检测到姿势\n",
    "        if results.pose_landmarks:\n",
    "            # 提取姿势特征\n",
    "            pose_features = []\n",
    "            for landmark in results.pose_landmarks.landmark:\n",
    "                pose_features.append(landmark.x)\n",
    "                pose_features.append(landmark.y)\n",
    "                pose_features.append(landmark.z)\n",
    "            \n",
    "            # 将骨架坐标转化为图像坐标\n",
    "            pose_landmarks = np.array([[lmk.x, lmk.y] for lmk in results.pose_landmarks.landmark])\n",
    "            pose_landmarks = (pose_landmarks * np.array([frame.shape[1], frame.shape[0]])).astype(np.int32)\n",
    "            \n",
    "            # 裁剪出手势区域，并进行手势识别\n",
    "            width = max(pose_landmarks[:, 0]) - min(pose_landmarks[:, 0])\n",
    "            height = max(pose_landmarks[:, 1]) - min(pose_landmarks[:, 1])\n",
    "            x1, y1 = max(0, min(pose_landmarks[:, 0]) - int(0.2 * width)), max(0, min(pose_landmarks[:, 1]) - int(0.2 * height))\n",
    "            x2, y2 = min(frame.shape[1], max(pose_landmarks[:, 0]) + int(0.2 * width)), min(frame.shape[0], max(pose_landmarks[:, 1]) + int(0.2 * height))\n",
    "            gesture = cv2.resize(cv2.cvtColor(frame[y1:y2, x1:x2], cv2.COLOR_RGB2GRAY), (64, 64))\n",
    "            gesture = np.expand_dims(gesture, axis=2)\n",
    "            gesture = np.expand_dims(gesture, axis=0)\n",
    "            prediction = model.predict(gesture)\n",
    "            action = 'Unknown'\n",
    "            if prediction[0][0] > 0.5:\n",
    "                action = 'Victory'\n",
    "                # 播放提示音\n",
    "                playsound('victory.mp3')\n",
    "            \n",
    "            # 在帧上显示识别结果\n",
    "            cv2.putText(frame, action, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # 在帧上绘制骨架\n",
    "            mp_pose.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "        # 显示帧\n",
    "        cv2.imshow('MediaPipe Pose Estimation', frame)\n",
    "\n",
    "        # 如果按下ESC键，则退出循环\n",
    "        if cv2.waitKey(10) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
