{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先确定数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def detect_license_plate(img):\n",
    "    \"\"\"\n",
    "    识别车牌\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    canny = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i in range(len(contours)):\n",
    "        cnt = contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "\n",
    "        if area < 2000 or area > 10000:\n",
    "            continue\n",
    "\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "\n",
    "        width, height = rect[1]\n",
    "        if height > width:\n",
    "            width, height = height, width\n",
    "\n",
    "        ratio = height / width\n",
    "        if ratio < 2 or ratio > 5:\n",
    "            continue\n",
    "\n",
    "        cv2.drawContours(img, [box], 0, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"License Plate Detection\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    img = cv2.imread(\"car1.jpg\")\n",
    "    detect_license_plate(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\n",
    "    \"D:\\code\\python\\machine_learning\\cnn_zuo_tu.h5\")\n",
    "# 读取图片\n",
    "img = cv2.imread('car1.jpg')\n",
    "\n",
    "# YOLOv3目标检测\n",
    "net = cv2.dnn.readNet(\"D:\\code\\python\\machine_learning\\yolo\\yolov3.weights\",\n",
    "                      \"D:\\code\\python\\machine_learning\\yolo\\yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"D:\\code\\python\\machine_learning\\yolo\\coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "height, width, channels = img.shape\n",
    "\n",
    "# 对图像进行预处理，包括缩放和二值化\n",
    "blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(\n",
    "    416, 416), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# 找出车牌区域\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # 对车牌区域进行裁剪\n",
    "        plate = img[y:y+h, x:x+w]\n",
    "\n",
    "        # 对裁剪后的车牌区域进行字符分割\n",
    "        gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "        contours, _ = cv2.findContours(\n",
    "            thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        char_list = []\n",
    "        for cnt in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "            ratio = h/w\n",
    "            if ratio > 1.5 and ratio < 3 and h/plate.shape[0] > 0.3:\n",
    "                cv2.rectangle(plate, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                roi = thresh[y:y+h, x:x+w]\n",
    "                roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "                roi = cv2.dilate(roi, (3, 3))\n",
    "                char_list.append((x, roi))\n",
    "\n",
    "        # 按字符位置从左到右排序\n",
    "        char_list = sorted(char_list, key=lambda x: x[0])\n",
    "\n",
    "        # 识别字符并输出结果\n",
    "        text = ''\n",
    "        for char in char_list:\n",
    "            x, roi = char\n",
    "            roi = np.array(roi, dtype=np.float32)\n",
    "            roi /= 255\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "            roi = np.expand_dims(roi, axis=3)\n",
    "            result = model.predict(roi)\n",
    "            result_number = np.argmax(result)\n",
    "            text += str(result_number)\n",
    "\n",
    "        print(\"车牌号码：\", text)\n",
    "        cv2.imshow(\"plate\", plate)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39mcar.jpg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# YOLOv3目标检测\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m net \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mdnn\u001b[39m.\u001b[39;49mreadNet(\u001b[39m\"\u001b[39;49m\u001b[39myolov3.weights\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39myolov3.cfg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m classes \u001b[39m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcoco.names\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'cv::dnn::dnn4_v20221220::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图片\n",
    "img = cv2.imread('car.jpg')\n",
    "\n",
    "# YOLOv3目标检测\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "height, width, channels = img.shape\n",
    "\n",
    "# 对图像进行预处理，包括缩放和二值化\n",
    "blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(416, 416), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "outs = net.forward(output_layers)\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * width)\n",
    "            center_y = int(detection[1] * height)\n",
    "            w = int(detection[2] * width)\n",
    "            h = int(detection[3] * height)\n",
    "            x = int(center_x - w / 2)\n",
    "            y = int(center_y - h / 2)\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# 找出车牌区域\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "for i in range(len(boxes)):\n",
    "    if i in indexes:\n",
    "        x, y, w, h = boxes[i]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# 对车牌区域进行裁剪\n",
    "plate = img[y:y+h, x:x+w]\n",
    "\n",
    "# 对裁剪后的车牌区域进行字符分割\n",
    "gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "...\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#好的，下面是车牌字符分割的Python代码示例。\n",
    "\n",
    "import cv2\n",
    "\n",
    "# 读取裁剪后的车牌图像\n",
    "plate_img = cv2.imread('car1.jpg')\n",
    "\n",
    "# 灰度化和二值化处理\n",
    "gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# 查找车牌字符的轮廓，并按照从左到右的顺序进行排序\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0])\n",
    "\n",
    "# 将每个字符的图像分别保存，并显示出来\n",
    "for i, contour in enumerate(contours):\n",
    "    # 获得每个字符的坐标、宽度和高度\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # 根据坐标和大小截取出每个字符的图像\n",
    "    char_img = plate_img[y:y+h, x:x+w]\n",
    "    # 将截取出来的字符图像保存为文件，文件名为字符的序号\n",
    "    cv2.imwrite(str(i) + '.jpg', char_img)\n",
    "    # 在原图上用矩形框标识出每个字符的位置\n",
    "    cv2.rectangle(plate_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    # 在窗口中显示每个字符的图像\n",
    "    cv2.imshow('Char '+str(i), char_img)\n",
    "\n",
    "# 在窗口中显示标识出字符位置的原图\n",
    "cv2.imshow('Plate', plate_img)\n",
    "\n",
    "# 等待用户按下任意键后退出程序\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#上面的代码首先读取了车牌图像，并将其转换为灰度图像，然后使用 OTSU 自适应二值化，将车牌字符变为白色，背景变为黑色。接着，使用 `cv2.findContours` 函数查找车牌字符的轮廓，按照从左到右的顺序进行排序，然后循环处理每个字符，截取出它的图像，保存为文件，并在原图上用矩形框标识出每个字符的位置。最后，在窗口中分别显示每个字符的图像和标识出字符位置的原图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red probability: 0.005276102824500159\n",
      "Blue probability: 0.0432005712472231\n",
      "Yellow probability: 0.09298635353855919\n"
     ]
    }
   ],
   "source": [
    "# 好的，以下是基于 OpenCV 的 Python 代码示例：\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('car.jpg')\n",
    "\n",
    "# 转换颜色空间\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# 创建颜色区间\n",
    "lower_red = np.array([0, 50, 50])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "lower_blue = np.array([100, 50, 50])\n",
    "upper_blue = np.array([130, 255, 255])\n",
    "lower_yellow = np.array([20, 50, 50])\n",
    "upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "# 提取车牌颜色\n",
    "mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "# 统计颜色像素数量\n",
    "red_pixels = cv2.countNonZero(mask_red)\n",
    "blue_pixels = cv2.countNonZero(mask_blue)\n",
    "yellow_pixels = cv2.countNonZero(mask_yellow)\n",
    "\n",
    "# 计算颜色概率分布\n",
    "total_pixels = img.shape[0] * img.shape[1]\n",
    "red_prob = red_pixels / total_pixels\n",
    "blue_prob = blue_pixels / total_pixels\n",
    "yellow_prob = yellow_pixels / total_pixels\n",
    "\n",
    "# 输出颜色概率分布\n",
    "print(\"Red probability:\", red_prob)\n",
    "print(\"Blue probability:\", blue_prob)\n",
    "print(\"Yellow probability:\", yellow_prob)\n",
    "\n",
    "# 显示图像和颜色区域\n",
    "cv2.imshow('Image', img)\n",
    "cv2.imshow('Red', mask_red)\n",
    "cv2.imshow('Blue', mask_blue)\n",
    "cv2.imshow('Yellow', mask_yellow)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# 在本示例中，我们使用 `cv2.inRange()` 函数提取颜色区间内的像素，并使用 `cv2.countNonZero()` 函数计算该颜色所占像素数量。最终，我们计算每个颜色概率分布，并输出结果。\n",
    "\n",
    "# 请注意，颜色区间的值是在 HSV 颜色空间下定义的，因为它对于颜色识别更有效。你可以根据你的需求修改颜色区间值。在本示例中，我们提取了红色、蓝色和黄色车牌。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.7.0\n",
      "['', '', 're', '«\\n«', '', '', '', '']\n",
      "\n",
      "\n",
      "车牌号码为： re«\n",
      "« blue\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "# 设置识别语言为英文\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "custom_config = r'-l eng --oem 3 --psm 6'\n",
    "\n",
    "def plate_detection(image):\n",
    "    # 转换为灰度图像\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 提取水平和垂直方向上的图像边缘\n",
    "    dx = cv2.Sobel(gray_img, cv2.CV_32F, 1, 0)\n",
    "    dy = cv2.Sobel(gray_img, cv2.CV_32F, 0, 1)\n",
    "    \n",
    "    # 取绝对值\n",
    "    dx = cv2.convertScaleAbs(dx)\n",
    "    dy = cv2.convertScaleAbs(dy)\n",
    "    \n",
    "    # 结合水平方向和垂直方向的边缘\n",
    "    edge_img = cv2.addWeighted(dx, 0.5, dy, 0.5, 0)\n",
    "    \n",
    "    # 使用二值化处理，生成二值图像\n",
    "    _, threshold_img = cv2.threshold(edge_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # 膨胀操作，提升连通性\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    morph_img = cv2.morphologyEx(threshold_img, cv2.MORPH_DILATE, kernel)\n",
    "    \n",
    "    # 在图像中查找指定形状的轮廓，这里是一个矩形\n",
    "    contours, hierarchy = cv2.findContours(morph_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 定位最大轮廓区域，即车牌所在的位置。因为矩形面积是宽*高，因此定位最大矩形区域即定位车牌位置\n",
    "    max_area = 0\n",
    "    plate_rect = None\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            plate_rect = cv2.boundingRect(contour)\n",
    "    \n",
    "    # 返回车牌位置矩形框\n",
    "    return plate_rect\n",
    "\n",
    "def segment_characters(image, plate_rect):\n",
    "    # 裁剪出车牌区域\n",
    "    x, y, w, h = plate_rect\n",
    "    plate_image = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # 将车牌进行腐蚀操作\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    eroded_plate_image = cv2.erode(plate_image, kernel, iterations=1)\n",
    "    \n",
    "    # 将车牌转换为灰度图像\n",
    "    gray_img = cv2.cvtColor(eroded_plate_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 使用二值化处理，生成二值图像\n",
    "    _, threshold_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # 使用开操作去除噪点\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening_img = cv2.morphologyEx(threshold_img, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # 查找图像中轮廓\n",
    "    contours, hierarchy = cv2.findContours(opening_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 裁剪并保存识别出的字符\n",
    "    segments = []\n",
    "    for contour in contours:\n",
    "        contour_rect = cv2.boundingRect(contour)\n",
    "        x1, y1, w1, h1 = contour_rect\n",
    "        aspect_ratio = w1 / h1\n",
    "        if 0.2 < aspect_ratio < 1.0:\n",
    "            segment = opening_img[y1:y1+h1, x1:x1+w1]\n",
    "            segments.append(segment)\n",
    "    \n",
    "    #返回字符片段\n",
    "    return segments\n",
    "\n",
    "def recognize_characters(segments):\n",
    "    # 识别每个字符\n",
    "    characters = []\n",
    "    for segment in segments:\n",
    "        character = pytesseract.image_to_string(segment, config=custom_config).strip()\n",
    "        characters.append(character)\n",
    "    \n",
    "    # 返回所有字符\n",
    "    return characters\n",
    "\n",
    "def recognize_color(image):\n",
    "    #将图像从BGR颜色空间转换到HSV颜色空间\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 设置HSV颜色阈值上下限值\n",
    "    lower_blue = np.array([100, 43, 46])\n",
    "    upper_blue = np.array([124, 255, 255])\n",
    "    \n",
    "    # 筛选符合指定颜色范围的像素点\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    \n",
    "    # 计算符合条件像素点的数量，设定数量阈值以确定车牌颜色\n",
    "    pixel_count = cv2.countNonZero(mask)\n",
    "    \n",
    "    # 如果符合条件像素点的数量大于设定阈值，则返回蓝色车牌，否则返回黄色车牌\n",
    "    if pixel_count > 2000:\n",
    "        return 'blue'\n",
    "    else:\n",
    "        return 'yellow'\n",
    "\n",
    "def recognize_plate(image):\n",
    "    # 定位车牌位置\n",
    "    plate_rect = plate_detection(image)\n",
    "    \n",
    "    # 分割字符\n",
    "    segments = segment_characters(image, plate_rect)\n",
    "\n",
    "    # 识别字符\n",
    "    characters = recognize_characters(segments)\n",
    "    print(characters)\n",
    "    print('\\n')    \n",
    "    # 识别车牌颜色\n",
    "    color = recognize_color(image)\n",
    "    \n",
    "    # 将字符和车牌颜色组合起来得到最终的车牌号码\n",
    "    plate_number = ''.join(characters) + ' ' + color\n",
    "    \n",
    "    return plate_number\n",
    "\n",
    "# 读入图像\n",
    "image = cv2.imread(r\"C:\\Users\\m0815\\Downloads\\archive\\images\\Cars1.png\")\n",
    "\n",
    "# 显示OpenCV版本\n",
    "print('OpenCV version:', cv2.__version__)\n",
    "\n",
    "# 车牌识别\n",
    "plate_number = recognize_plate(image)\n",
    "\n",
    "# 显示识别结果\n",
    "print('车牌号码为：', plate_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "img=cv2.imread(r\"C:\\Users\\m0815\\Downloads\\archive\\images\\Cars1.png\")\n",
    "characters=[]\n",
    "# 设置识别语言为英文\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "custom_config = r'-l eng --oem 3 --psm 6'\n",
    "character = pytesseract.image_to_string(img)\n",
    "# characters.append(character)\n",
    "print(character)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
